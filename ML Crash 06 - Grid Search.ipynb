{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd84e78",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "We can change how a model learns with it's parameters. Here we use combinations of sets of values forming a grid of values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c0cd0",
   "metadata": {},
   "source": [
    "**Using grid search default parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4282fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0886952a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "169da019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b833ca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f910a112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df88a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b6e1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the logistic model for classifying the iris flowers.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Creating the model\n",
    "#setting max_iter to a higher value \n",
    "#to ensure that the model finds a result.\n",
    "\n",
    "logit = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "# The default value for C in a logistic regression model is 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2749fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000)\n"
     ]
    }
   ],
   "source": [
    "#fit the model to the data.\n",
    "\n",
    "m=logit.fit(X,y)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a88a2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model with the score method.\n",
    "s=logit.score(X,y)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de49baa",
   "metadata": {},
   "source": [
    "With the default setting of C = 1, we achieved a score of 0.973."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126ff32",
   "metadata": {},
   "source": [
    "## Implementing Grid Search\n",
    "**This time we will set a range of values for C.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "939937c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 0.9666666666666667, 0.9733333333333334, 0.9733333333333334, 0.98, 0.98, 0.9866666666666667, 0.9866666666666667]\n"
     ]
    }
   ],
   "source": [
    "C = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]\n",
    "\n",
    "#create a for loop to change out the values of C \n",
    "#and evaluate the model with each change.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for choice in C:\n",
    "  logit.set_params(C=choice)\n",
    "  logit.fit(X, y)\n",
    "  scores.append(logit.score(X, y))\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896a0e4",
   "metadata": {},
   "source": [
    "increasing C to 1.75 the model experienced increased accuracy.<br><br>\n",
    "increasing C beyond this amount does not help increase model accuracy.<br>\n",
    "<br>\n",
    "We scored our logistic regression model by using the same data that was used to train it. If the model corresponds too closely to that data, it may not be great at predicting unseen data. This statistical error is known as over fitting.\n",
    "<br><br>\n",
    "We can put aside a portion of our data and use it specifically for the purpose of testing the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89107deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
